{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APL and lLN2f_b\n",
    "(Note: This file gets too big to push to Git when all the fetch synapses cells are run.)\n",
    "This notebook fetchs skeletons and connections for some of the large inhibitory neurons that we want to compare oviIN to. The connections obtained from fetch_synapse_connections are exported to a csv file since those can take some time to run. \n",
    "Finally, the synaptic sites are visualized on the skeletons and color-coded for their cluster identity in the whole brain modularity done by Alex. The cluster identity is the cluster that the synaptic partner belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish Neuprint client\n",
    "from neuprint import Client\n",
    "# remove my token before making notebook public\n",
    "c = Client('neuprint.janelia.org', dataset='hemibrain:v1.2.1', token='eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImdnMjExNEBjb2x1bWJpYS5lZHUiLCJsZXZlbCI6Im5vYXV0aCIsImltYWdlLXVybCI6Imh0dHBzOi8vbGgzLmdvb2dsZXVzZXJjb250ZW50LmNvbS9hLS9BT2gxNEdpb1lJLUVPLWdidGxPRTh6SmQ0eF9ZQ1Y4ZHF0YVFjWGlHeG5CMz1zOTYtYz9zej01MD9zej01MCIsImV4cCI6MTgxMDUyOTYzNH0.jv9eR0SH5RhfBdXrtp4r-dDFOhcsT8GBbE4v69ysCKs') \n",
    "c.fetch_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"aa6b0b41-97a7-4d5e-93cb-706b98c75c5b\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"aa6b0b41-97a7-4d5e-93cb-706b98c75c5b\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"aa6b0b41-97a7-4d5e-93cb-706b98c75c5b\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import important stuff here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import bokeh\n",
    "#import hvplot.pandas\n",
    "#import holoviews as hv\n",
    "\n",
    "import gc\n",
    "\n",
    "import bokeh.palettes\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information is fetched for 3 neuron types: oviIN, APL, and lLN2F_b; including their skeletons which are then visualized together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyId</th>\n",
       "      <th>instance</th>\n",
       "      <th>type</th>\n",
       "      <th>pre</th>\n",
       "      <th>post</th>\n",
       "      <th>downstream</th>\n",
       "      <th>upstream</th>\n",
       "      <th>mito</th>\n",
       "      <th>size</th>\n",
       "      <th>status</th>\n",
       "      <th>cropped</th>\n",
       "      <th>statusLabel</th>\n",
       "      <th>cellBodyFiber</th>\n",
       "      <th>somaRadius</th>\n",
       "      <th>somaLocation</th>\n",
       "      <th>roiInfo</th>\n",
       "      <th>notes</th>\n",
       "      <th>inputRois</th>\n",
       "      <th>outputRois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423101189</td>\n",
       "      <td>oviIN_R</td>\n",
       "      <td>oviIN</td>\n",
       "      <td>6863</td>\n",
       "      <td>23029</td>\n",
       "      <td>60603</td>\n",
       "      <td>23029</td>\n",
       "      <td>2472</td>\n",
       "      <td>10033593370</td>\n",
       "      <td>Traced</td>\n",
       "      <td>False</td>\n",
       "      <td>Roughly traced</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'SNP(R)': {'pre': 4773, 'post': 13645, 'downs...</td>\n",
       "      <td>None</td>\n",
       "      <td>[ATL(R), CAN(R), CRE(-ROB,-RUB)(R), CRE(-RUB)(...</td>\n",
       "      <td>[CAN(R), CRE(-ROB,-RUB)(R), CRE(-RUB)(L), CRE(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425790257</td>\n",
       "      <td>APL_R</td>\n",
       "      <td>APL</td>\n",
       "      <td>16190</td>\n",
       "      <td>127151</td>\n",
       "      <td>121662</td>\n",
       "      <td>127151</td>\n",
       "      <td>7622</td>\n",
       "      <td>23360457066</td>\n",
       "      <td>Traced</td>\n",
       "      <td>False</td>\n",
       "      <td>Roughly traced</td>\n",
       "      <td>None</td>\n",
       "      <td>900.1</td>\n",
       "      <td>[2995, 23785, 20800]</td>\n",
       "      <td>{'MB(R)': {'pre': 15542, 'post': 122975, 'down...</td>\n",
       "      <td>None</td>\n",
       "      <td>[AL(R), AL-VP2(R), ATL(L), ATL(R), AVLP(R), CA...</td>\n",
       "      <td>[AL(R), AL-VP2(R), ATL(L), CA(R), CRE(-ROB,-RU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>485934965</td>\n",
       "      <td>oviIN_L</td>\n",
       "      <td>oviIN</td>\n",
       "      <td>6542</td>\n",
       "      <td>15998</td>\n",
       "      <td>58310</td>\n",
       "      <td>15998</td>\n",
       "      <td>2208</td>\n",
       "      <td>8493821787</td>\n",
       "      <td>Traced</td>\n",
       "      <td>False</td>\n",
       "      <td>Roughly traced</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'SNP(L)': {'pre': 4184, 'post': 10529, 'downs...</td>\n",
       "      <td>None</td>\n",
       "      <td>[ATL(L), CRE(-ROB,-RUB)(R), CRE(-RUB)(L), CRE(...</td>\n",
       "      <td>[ATL(L), CRE(-ROB,-RUB)(R), CRE(-RUB)(L), CRE(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1640909284</td>\n",
       "      <td>lLN2F_b(Full)_R</td>\n",
       "      <td>lLN2F_b</td>\n",
       "      <td>7998</td>\n",
       "      <td>27355</td>\n",
       "      <td>31781</td>\n",
       "      <td>27355</td>\n",
       "      <td>3069</td>\n",
       "      <td>9656560959</td>\n",
       "      <td>Traced</td>\n",
       "      <td>False</td>\n",
       "      <td>Roughly traced</td>\n",
       "      <td>AVM02</td>\n",
       "      <td>741.5</td>\n",
       "      <td>[13533, 33133, 27192]</td>\n",
       "      <td>{'AL(R)': {'pre': 7989, 'post': 27329, 'downst...</td>\n",
       "      <td>AL-LN2L (Tanaka et al. JCN 2012)</td>\n",
       "      <td>[AL(R), AL-D(R), AL-DA1(R), AL-DA2(R), AL-DA3(...</td>\n",
       "      <td>[AL(R), AL-D(R), AL-DA1(R), AL-DA2(R), AL-DA3(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5813024698</td>\n",
       "      <td>lLN2F_b(Full)_R</td>\n",
       "      <td>lLN2F_b</td>\n",
       "      <td>8152</td>\n",
       "      <td>26039</td>\n",
       "      <td>31985</td>\n",
       "      <td>26039</td>\n",
       "      <td>2828</td>\n",
       "      <td>9671459921</td>\n",
       "      <td>Traced</td>\n",
       "      <td>False</td>\n",
       "      <td>Roughly traced</td>\n",
       "      <td>AVM02</td>\n",
       "      <td>741.5</td>\n",
       "      <td>[13436, 33797, 26376]</td>\n",
       "      <td>{'AL(R)': {'pre': 8136, 'post': 26015, 'downst...</td>\n",
       "      <td>AL-LN2L (Tanaka et al. JCN 2012)</td>\n",
       "      <td>[AL(R), AL-D(R), AL-DA1(R), AL-DA2(R), AL-DA3(...</td>\n",
       "      <td>[AL(R), AL-D(R), AL-DA1(R), AL-DA2(R), AL-DA3(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bodyId         instance     type    pre    post  downstream  upstream  \\\n",
       "0   423101189          oviIN_R    oviIN   6863   23029       60603     23029   \n",
       "1   425790257            APL_R      APL  16190  127151      121662    127151   \n",
       "2   485934965          oviIN_L    oviIN   6542   15998       58310     15998   \n",
       "3  1640909284  lLN2F_b(Full)_R  lLN2F_b   7998   27355       31781     27355   \n",
       "4  5813024698  lLN2F_b(Full)_R  lLN2F_b   8152   26039       31985     26039   \n",
       "\n",
       "   mito         size  status  cropped     statusLabel cellBodyFiber  \\\n",
       "0  2472  10033593370  Traced    False  Roughly traced          None   \n",
       "1  7622  23360457066  Traced    False  Roughly traced          None   \n",
       "2  2208   8493821787  Traced    False  Roughly traced          None   \n",
       "3  3069   9656560959  Traced    False  Roughly traced         AVM02   \n",
       "4  2828   9671459921  Traced    False  Roughly traced         AVM02   \n",
       "\n",
       "   somaRadius           somaLocation  \\\n",
       "0         NaN                   None   \n",
       "1       900.1   [2995, 23785, 20800]   \n",
       "2         NaN                   None   \n",
       "3       741.5  [13533, 33133, 27192]   \n",
       "4       741.5  [13436, 33797, 26376]   \n",
       "\n",
       "                                             roiInfo  \\\n",
       "0  {'SNP(R)': {'pre': 4773, 'post': 13645, 'downs...   \n",
       "1  {'MB(R)': {'pre': 15542, 'post': 122975, 'down...   \n",
       "2  {'SNP(L)': {'pre': 4184, 'post': 10529, 'downs...   \n",
       "3  {'AL(R)': {'pre': 7989, 'post': 27329, 'downst...   \n",
       "4  {'AL(R)': {'pre': 8136, 'post': 26015, 'downst...   \n",
       "\n",
       "                              notes  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                              None   \n",
       "3  AL-LN2L (Tanaka et al. JCN 2012)   \n",
       "4  AL-LN2L (Tanaka et al. JCN 2012)   \n",
       "\n",
       "                                           inputRois  \\\n",
       "0  [ATL(R), CAN(R), CRE(-ROB,-RUB)(R), CRE(-RUB)(...   \n",
       "1  [AL(R), AL-VP2(R), ATL(L), ATL(R), AVLP(R), CA...   \n",
       "2  [ATL(L), CRE(-ROB,-RUB)(R), CRE(-RUB)(L), CRE(...   \n",
       "3  [AL(R), AL-D(R), AL-DA1(R), AL-DA2(R), AL-DA3(...   \n",
       "4  [AL(R), AL-D(R), AL-DA1(R), AL-DA2(R), AL-DA3(...   \n",
       "\n",
       "                                          outputRois  \n",
       "0  [CAN(R), CRE(-ROB,-RUB)(R), CRE(-RUB)(L), CRE(...  \n",
       "1  [AL(R), AL-VP2(R), ATL(L), CA(R), CRE(-ROB,-RU...  \n",
       "2  [ATL(L), CRE(-ROB,-RUB)(R), CRE(-RUB)(L), CRE(...  \n",
       "3  [AL(R), AL-D(R), AL-DA1(R), AL-DA2(R), AL-DA3(...  \n",
       "4  [AL(R), AL-D(R), AL-DA1(R), AL-DA2(R), AL-DA3(...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuprint import fetch_neurons\n",
    "from neuprint import NeuronCriteria as NC\n",
    "\n",
    "bigneurons_df, roi_counts_df = fetch_neurons(NC(type=['lLN2F_b','APL','oviIN']))\n",
    "bigneurons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download some skeletons as DataFrames and attach columns for bodyId and color\n",
    "skeletons = []\n",
    "for i, bodyId in enumerate(bigneurons_df['bodyId'].unique()):\n",
    "    s = c.fetch_skeleton(bodyId, format='pandas')\n",
    "    s['bodyId'] = bodyId\n",
    "    s['color'] = bokeh.palettes.Accent[5][i]\n",
    "    #s['color'] = bokeh.palettes.Greys[3][i]\n",
    "    skeletons.append(s)\n",
    "\n",
    "# Combine into one big table for convenient processing\n",
    "skeletons = pd.concat(skeletons, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join parent/child nodes for plotting as line segments below.\n",
    "# (Using each row's 'link' (parent) ID, find the row with matching rowId.)\n",
    "segments = skeletons.merge(skeletons, 'inner',\n",
    "                           left_on=['bodyId', 'link'],\n",
    "                           right_on=['bodyId', 'rowId'],\n",
    "                           suffixes=['_child', '_parent'])\n",
    "\n",
    "del skeletons, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge type label onto segments\n",
    "segments = segments.merge(bigneurons_df[['bodyId','type']], 'inner', left_on='bodyId', right_on='bodyId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure()\n",
    "p.y_range.flipped = True\n",
    "\n",
    "# Plot skeleton segments (in 2D)\n",
    "p.segment(x0='x_child', x1='x_parent',\n",
    "          y0='z_child', y1='z_parent',\n",
    "          color='color_child',\n",
    "          source=segments)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster synapse placement\n",
    "This is to see whether the synapses segrate by cluster/module on the arbor of these neurons in the same way that they do for oviIN - particularly for inputs. The inputs to oviIN (from pre-synaptic partners) had a striking pattern of segregation by coarse modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to folder with hemibrain modularity data\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/ggutierr/My Drive (ggutierr@barnard.edu)/GitHub/oviIN-analyses-gabrielle/hemibrain_preprocessed/preprocessed-v1.2')\n",
    "\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read preprocessed_nodes which contains Alex's modularity data\n",
    "# changed the dtype of inputRois to string from object but it actually doesn't matter since in the for loop this info is object in row\n",
    "HB_df = pd.read_csv('preprocessed_nodes.csv',dtype={'inputRois':'string'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All I care about are the coarse modules for now since the distinct modules become difficult to visualize when there are too many of them. Also, if there isn't an effect with the coarse modules, then I have no reason to think that something interesting will be found with finer modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_mods = HB_df[['id','0.0']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synaptic input modules on APL\n",
    "APL is a large inhibitory neuron that is known to do divisive normalization. The synapse connections can be loaded if they have been fetched and saved before, or they can be fetched and saved if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open big_neuron_specs folder\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/ggutierr/My Drive (ggutierr@barnard.edu)/GitHub/oviIN-analyses-gabrielle/big_neuron_specs')\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read synapse connections from the specs folder or run the following code blocks to generate and export the data\n",
    "APL_pre_syns = pd.read_csv('APL_pre_syns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuprint import fetch_synapse_connections\n",
    "from neuprint import merge_neuron_properties\n",
    "from neuprint import fetch_synapses, NeuronCriteria as NC, SynapseCriteria as SC\n",
    "from neuprint import fetch_neurons\n",
    "\n",
    "APLr_bodyID = 425790257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fetch synapse connections for the right APL neuron\n",
    "APL_pre_syns = fetch_synapse_connections(None, APLr_bodyID, SC(primary_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this in the specs folder\n",
    "APL_pre_syns.to_csv('APL_pre_syns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the types of the pre-synaptic neurons and merge type info onto APL_pre_syns\n",
    "pre_neurons, _ = fetch_neurons(APL_pre_syns['bodyId_pre'].unique())\n",
    "APL_pre_syns = merge_neuron_properties(pre_neurons, APL_pre_syns, 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APL_pre_modules = APL_pre_syns.merge(coarse_mods, how='inner', left_on='bodyId_pre', right_on='id')\n",
    "\n",
    "del APL_pre_syns, pre_neurons\n",
    "APL_pre_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a colormap so that each module gets a different color\n",
    "colormap = dict(zip(APL_pre_modules['0.0'].value_counts().index, bokeh.palettes.Category10[8]))\n",
    "\n",
    "# add the color information to the df\n",
    "APL_pre_modules['color'] = APL_pre_modules['0.0'].map(colormap)\n",
    "\n",
    "# get APL skeleton segments\n",
    "segmentsAPL = segments.loc[segments['bodyId'] == APLr_bodyID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pretty skeleton with synapses on it showing inputs and outputs in different colors\n",
    "pmpre = figure(title=\"Post sites from pre-synaptic partners on APL_R according to coarse modules\")\n",
    "pmpre.y_range.flipped = True\n",
    "\n",
    "# Plot skeleton segments (in 2D)\n",
    "pmpre.segment(x0='x_child', x1='x_parent',\n",
    "          y0='z_child', y1='z_parent',\n",
    "          color='color_child',\n",
    "          source=segmentsAPL)\n",
    "\n",
    "# default point size is 4\n",
    "#pmpre.scatter('x_post', 'z_post', color='color', legend_group='0.0', source=APL_pre_modules[APL_pre_modules['0.0']==1], size=2)\n",
    "pmpre.scatter('x_post', 'z_post', color='color', legend_group='0.0', source=APL_pre_modules, size=1)\n",
    "\n",
    "show(pmpre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the vast majority of inputs to APL come from cluster 5, it is a bit hard to see what else is there. Below, I make 7 panels showing each of the clusters on the arbor separately. There appears to be some segregation of inputs but I would have to plot the comparison for oviIN in the same way to make it a good comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import row, column, gridplot\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs=[]\n",
    "for cluster in clusters: #APL_pre_modules['0.0'].unique():\n",
    "    # make a pretty skeleton with synapses on it showing inputs and outputs in different colors\n",
    "    pmpre = figure(title=\"Post sites from pre-synaptic partners on APL_R according to coarse modules\",width=300, height=300)\n",
    "    pmpre.y_range.flipped = True\n",
    "\n",
    "    # Plot skeleton segments (in 2D)\n",
    "    pmpre.segment(x0='x_child', x1='x_parent',\n",
    "          y0='z_child', y1='z_parent',\n",
    "          color='color_child',\n",
    "          source=segmentsAPL)\n",
    "\n",
    "    # default point size is 4\n",
    "    pmpre.scatter('x_post', 'z_post', color='color', legend_group='0.0', source=APL_pre_modules[APL_pre_modules['0.0']==cluster], size=2)\n",
    "\n",
    "    figs.append(pmpre)\n",
    "\n",
    "g = gridplot(figs, ncols=4)\n",
    "show(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del APL_pre_modules, segmentsAPL\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synaptic input modules on oviIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/ggutierr/My Drive (ggutierr@barnard.edu)/GitHub/oviIN-analyses-gabrielle/oviIN_specs')\n",
    "path = os.getcwd()\n",
    "\n",
    "ovi_pre_syns = pd.read_csv('ovi_pre_syns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body ID of oviIN_R from Neuprint\n",
    "oviINr_bodyID = 423101189\n",
    "\n",
    "# Retrieve the types of the pre-synaptic neurons and merge type info onto APL_pre_syns\n",
    "pre_neurons, _ = fetch_neurons(ovi_pre_syns['bodyId_pre'].unique())\n",
    "ovi_pre_syns = merge_neuron_properties(pre_neurons, ovi_pre_syns, 'type')\n",
    "\n",
    "# merge coarse modularity data onto ovi_pre_syns\n",
    "ovi_pre_modules = ovi_pre_syns.merge(coarse_mods, how='inner', left_on='bodyId_pre', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a colormap so that each module gets a different color\n",
    "colormap = dict(zip(ovi_pre_modules['0.0'].value_counts().index, bokeh.palettes.Category10[8]))\n",
    "\n",
    "# add the color information to the df\n",
    "ovi_pre_modules['color'] = ovi_pre_modules['0.0'].map(colormap)\n",
    "\n",
    "# get APL skeleton segments\n",
    "segments_ovi = segments.loc[segments['bodyId'] == oviINr_bodyID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs=[]\n",
    "for cluster in clusters: #ovi_pre_modules['0.0'].unique():\n",
    "    # make a pretty skeleton with synapses on it showing inputs and outputs in different colors\n",
    "    pmpre = figure(title=\"Post sites from pre-synaptic partners on oviIN_R according to coarse modules\",width=300, height=300)\n",
    "    pmpre.y_range.flipped = True\n",
    "\n",
    "    # Plot skeleton segments (in 2D)\n",
    "    pmpre.segment(x0='x_child', x1='x_parent',\n",
    "          y0='z_child', y1='z_parent',\n",
    "          color='color_child',\n",
    "          source=segments_ovi)\n",
    "\n",
    "    # default point size is 4\n",
    "    pmpre.scatter('x_post', 'z_post', color='color', legend_group='0.0', source=ovi_pre_modules[ovi_pre_modules['0.0']==cluster], size=2)\n",
    "\n",
    "    figs.append(pmpre)\n",
    "\n",
    "g = gridplot(figs, ncols=4)\n",
    "show(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synaptic input modules on lLN2F_b\n",
    "This neuron has a striking consistency in that it almost exclusively gets its inputs from module #4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the big_neuron_specs folder\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/ggutierr/My Drive (ggutierr@barnard.edu)/GitHub/oviIN-analyses-gabrielle/big_neuron_specs')\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read synapse connections from the specs folder or run the following code blocks to generate and export the data\n",
    "lLN_pre_syns = pd.read_csv('lLN_pre_syns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuprint import fetch_synapse_connections\n",
    "from neuprint import merge_neuron_properties\n",
    "from neuprint import fetch_synapses, NeuronCriteria as NC, SynapseCriteria as SC\n",
    "from neuprint import fetch_neurons\n",
    "\n",
    "# just grab the first lLN2F_b body ID\n",
    "lLN2F_b_bodyId = bigneurons_df[bigneurons_df['type']=='lLN2F_b']['bodyId'].values[0]\n",
    "lLN_pre_syns = fetch_synapse_connections(None, lLN2F_b_bodyId, SC(primary_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this in the specs folder\n",
    "lLN_pre_syns.to_csv('lLN_pre_syns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the types of the pre-synaptic neurons and merge type info onto lLN_pre_syns\n",
    "pre_neurons, _ = fetch_neurons(lLN_pre_syns['bodyId_pre'].unique())\n",
    "lLN_pre_syns = merge_neuron_properties(pre_neurons, lLN_pre_syns, 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lLN_pre_modules = lLN_pre_syns.merge(coarse_mods, how='inner', left_on='bodyId_pre', right_on='id')\n",
    "lLN_pre_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a colormap so that each module gets a different color\n",
    "colormap = dict(zip(lLN_pre_modules['0.0'].value_counts().index, bokeh.palettes.Category10[8]))\n",
    "\n",
    "# add the color information to the df\n",
    "lLN_pre_modules['color'] = lLN_pre_modules['0.0'].map(colormap)\n",
    "\n",
    "# get skeleton segments\n",
    "segmentslLN = segments.loc[segments['bodyId'] == lLN2F_b_bodyId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs=[]\n",
    "for cluster in clusters: \n",
    "    # make a pretty skeleton with synapses on it showing inputs and outputs in different colors\n",
    "    pmpre = figure(title=\"Post sites from pre-synaptic partners on lLN2F_b according to coarse modules\",width=300, height=300)\n",
    "    pmpre.y_range.flipped = True\n",
    "\n",
    "    # Plot skeleton segments (in 2D)\n",
    "    pmpre.segment(x0='x_child', x1='x_parent',\n",
    "          y0='z_child', y1='z_parent',\n",
    "          color='color_child',\n",
    "          source=segmentslLN)\n",
    "\n",
    "    # default point size is 4\n",
    "    pmpre.scatter('x_post', 'z_post', color='color', legend_group='0.0', source=lLN_pre_modules[lLN_pre_modules['0.0']==cluster], size=2)\n",
    "\n",
    "    figs.append(pmpre)\n",
    "\n",
    "g = gridplot(figs, ncols=4)\n",
    "show(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synaptic output modules on APL\n",
    "Play the same game but now on the output sites of APL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/ggutierr/My Drive (ggutierr@barnard.edu)/GitHub/oviIN-analyses-gabrielle/big_neuron_specs')\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read synapse connections from the specs folder or run the following code blocks to generate and export the data\n",
    "APL_post_syns = pd.read_csv('APL_post_syns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuprint import fetch_synapse_connections\n",
    "from neuprint import merge_neuron_properties\n",
    "from neuprint import fetch_synapses, NeuronCriteria as NC, SynapseCriteria as SC\n",
    "from neuprint import fetch_neurons\n",
    "\n",
    "APLr_bodyID = 425790257\n",
    "APL_post_syns = fetch_synapse_connections(APLr_bodyID, None, SC(primary_only=True), batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this in the specs folder\n",
    "APL_post_syns.to_csv('APL_post_syns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the types of the post-synaptic neurons and merge type info onto APL_post_syns\n",
    "post_neurons, _ = fetch_neurons(APL_post_syns['bodyId_post'].unique())\n",
    "APL_post_syns = merge_neuron_properties(post_neurons, APL_post_syns, 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APL_post_modules = APL_post_syns.merge(coarse_mods, how='inner', left_on='bodyId_pre', right_on='id')\n",
    "\n",
    "del APL_post_syns, post_neurons\n",
    "APL_post_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a colormap so that each module gets a different color\n",
    "colormap = dict(zip(APL_post_modules['0.0'].value_counts().index, bokeh.palettes.Category10[8]))\n",
    "\n",
    "# add the color information to the df\n",
    "APL_post_modules['color'] = APL_post_modules['0.0'].map(colormap)\n",
    "\n",
    "# get APL skeleton segments\n",
    "segmentsAPL = segments.loc[segments['bodyId'] == APLr_bodyID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs=[]\n",
    "for cluster in clusters: #APL_pre_modules['0.0'].unique():\n",
    "    # make a pretty skeleton with synapses on it showing inputs and outputs in different colors\n",
    "    p = figure(title=\"Post sites from post-synaptic partners on APL_R according to coarse modules\",width=300, height=300)\n",
    "    p.y_range.flipped = True\n",
    "\n",
    "    # Plot skeleton segments (in 2D)\n",
    "    p.segment(x0='x_child', x1='x_parent',\n",
    "          y0='z_child', y1='z_parent',\n",
    "          color='color_child',\n",
    "          source=segmentsAPL)\n",
    "\n",
    "    # default point size is 4\n",
    "    p.scatter('x_post', 'z_post', color='color', legend_group='0.0', source=APL_post_modules[APL_post_modules['0.0']==cluster], size=2)\n",
    "\n",
    "    figs.append(p)\n",
    "\n",
    "g = gridplot(figs, ncols=4)\n",
    "show(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synaptic output modules on oviIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the oviIN_specs folder\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/ggutierr/My Drive (ggutierr@barnard.edu)/GitHub/oviIN-analyses-gabrielle/oviIN_specs')\n",
    "path = os.getcwd()\n",
    "\n",
    "ovi_post_syns = pd.read_csv('ovi_post_syns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body ID of oviIN_R from Neuprint\n",
    "oviINr_bodyID = 423101189\n",
    "\n",
    "# Retrieve the types of the post-synaptic neurons and merge type info onto ovi_post_syns\n",
    "post_neurons, _ = fetch_neurons(ovi_post_syns['bodyId_post'].unique())\n",
    "ovi_post_syns = merge_neuron_properties(post_neurons, ovi_post_syns, 'type')\n",
    "\n",
    "# merge coarse modularity data onto ovi_post_syns\n",
    "ovi_post_modules = ovi_post_syns.merge(coarse_mods, how='inner', left_on='bodyId_post', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a colormap so that each module gets a different color\n",
    "colormap = dict(zip(ovi_post_modules['0.0'].value_counts().index, bokeh.palettes.Category10[8]))\n",
    "\n",
    "# add the color information to the df\n",
    "ovi_post_modules['color'] = ovi_post_modules['0.0'].map(colormap)\n",
    "\n",
    "# get APL skeleton segments\n",
    "segments_ovi = segments.loc[segments['bodyId'] == oviINr_bodyID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs=[]\n",
    "for cluster in clusters: #ovi_pre_modules['0.0'].unique():\n",
    "    # make a pretty skeleton with synapses on it showing inputs and outputs in different colors\n",
    "    p = figure(title=\"Post sites from post-synaptic partners on oviIN_R according to coarse modules\",width=300, height=300)\n",
    "    p.y_range.flipped = True\n",
    "\n",
    "    # Plot skeleton segments (in 2D)\n",
    "    p.segment(x0='x_child', x1='x_parent',\n",
    "          y0='z_child', y1='z_parent',\n",
    "          color='color_child',\n",
    "          source=segments_ovi)\n",
    "\n",
    "    # default point size is 4\n",
    "    p.scatter('x_post', 'z_post', color='color', legend_group='0.0', source=ovi_post_modules[ovi_post_modules['0.0']==cluster], size=2)\n",
    "\n",
    "    figs.append(p)\n",
    "\n",
    "g = gridplot(figs, ncols=4)\n",
    "show(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synaptic output modules of lLN2F_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the big_neuron_specs folder\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/ggutierr/My Drive (ggutierr@barnard.edu)/GitHub/oviIN-analyses-gabrielle/big_neuron_specs')\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read synapse connections from the specs folder or run the following code blocks to generate and export the data\n",
    "lLN_post_syns = pd.read_csv('lLN_post_syns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuprint import fetch_synapse_connections\n",
    "from neuprint import merge_neuron_properties\n",
    "from neuprint import fetch_synapses, NeuronCriteria as NC, SynapseCriteria as SC\n",
    "from neuprint import fetch_neurons\n",
    "\n",
    "# just grab the first lLN2F_b body ID\n",
    "lLN2F_b_bodyId = bigneurons_df[bigneurons_df['type']=='lLN2F_b']['bodyId'].values[0]\n",
    "lLN_post_syns = fetch_synapse_connections(lLN2F_b_bodyId, None, SC(primary_only=True), batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this in the specs folder\n",
    "lLN_post_syns.to_csv('lLN_post_syns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the types of the post-synaptic neurons and merge type info onto lLN_post_syns\n",
    "post_neurons, _ = fetch_neurons(lLN_post_syns['bodyId_post'].unique())\n",
    "lLN_post_syns = merge_neuron_properties(post_neurons, lLN_post_syns, 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lLN_post_modules = lLN_post_syns.merge(coarse_mods, how='inner', left_on='bodyId_post', right_on='id')\n",
    "lLN_post_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a colormap so that each module gets a different color\n",
    "colormap = dict(zip(lLN_post_modules['0.0'].value_counts().index, bokeh.palettes.Category10[8]))\n",
    "\n",
    "# add the color information to the df\n",
    "lLN_post_modules['color'] = lLN_post_modules['0.0'].map(colormap)\n",
    "\n",
    "# get skeleton segments\n",
    "segmentslLN = segments.loc[segments['bodyId'] == lLN2F_b_bodyId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs=[]\n",
    "for cluster in clusters: \n",
    "    # make a pretty skeleton with synapses on it showing inputs and outputs in different colors\n",
    "    p = figure(title=\"Post sites from post-synaptic partners on lLN2F_b according to coarse modules\",width=300, height=300)\n",
    "    p.y_range.flipped = True\n",
    "\n",
    "    # Plot skeleton segments (in 2D)\n",
    "    p.segment(x0='x_child', x1='x_parent',\n",
    "          y0='z_child', y1='z_parent',\n",
    "          color='color_child',\n",
    "          source=segmentslLN)\n",
    "\n",
    "    # default point size is 4\n",
    "    p.scatter('x_post', 'z_post', color='color', legend_group='0.0', source=lLN_post_modules[lLN_post_modules['0.0']==cluster], size=2)\n",
    "\n",
    "    figs.append(p)\n",
    "\n",
    "g = gridplot(figs, ncols=4)\n",
    "show(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, what I can say about what makes oviIN distinct from the other large inhibitory neurons is that oviIN communicates with more output modules than the others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuprint import fetch_skeleton\n",
    "# Download some skeletons as DataFrames and attach columns for bodyId and color\n",
    "skeletons = []\n",
    "\n",
    "# could add more skeletons with a for loop\n",
    "s = c.fetch_skeleton(oviINr_bodyID, format='pandas')\n",
    "s['bodyId'] = oviINr_bodyID\n",
    "s['color'] = bokeh.palettes.Greys[3][1]\n",
    "skeletons.append(s)\n",
    "\n",
    "# Combine into one big table for convenient processing\n",
    "skeletons = pd.concat(skeletons, ignore_index=True)\n",
    "\n",
    "# Join parent/child nodes for plotting as line segments below.\n",
    "# (Using each row's 'link' (parent) ID, find the row with matching rowId.)\n",
    "segments = skeletons.merge(skeletons, 'inner',\n",
    "                           left_on=['bodyId', 'link'],\n",
    "                           right_on=['bodyId', 'rowId'],\n",
    "                           suffixes=['_child', '_parent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(title=\"oviIN_R\")\n",
    "p.y_range.flipped = True\n",
    "\n",
    "# Plot skeleton segments (in 2D)\n",
    "p.segment(x0='x_child', x1='x_parent',\n",
    "          y0='z_child', y1='z_parent',\n",
    "          color='color_child',\n",
    "          source=segments)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modularity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
